# 100 Days Of Code - Log

### Day 1: June 28th, 2018

**Today's Progress**: Tried out FreeCodeCamp.org, got bored and started dabbling with Python. Fiddling around with mean, median and mode functions that are part of the Python library. I'm doing so becaue I am currently taking statistics.

**Thoughts:** I struggled with remembering syntax of Python but nothing a little Google searching couldn't do.
**Link:** https://github.com/gantgarrett/Projects/blob/master/meanmedianmode.py


### Day 2: June 29th, 2018

**Today's Progress**: Currently reading "Automate the Boring Stuff With Python" to understand the Python language better. I am understanding the language but there are concepts I'm still trying to wrap my head around like nested for loops and being able to manipulate lists and tuples. The author includes coding exercises after each chapter so I attempt them but I end up not finding my answer in the book so I do some Google searching to see what others have done. It helps bring context to the exercises. It feels like I spoil the fun of figuring out the programs myself but there's no way I could come up with the code myself quite yet... yet.

**Thoughts**: Python is flexible and easy to read compared to most languages I have worked with. If I keep practicing (which is why I'm donig 100-days-of-code) I know I will become fluent in the language.

### Day 3: June 30th, 2018

**Today's Progress**: I went on codeacademy.com to work on SQL. I find SQL interesting because it is database organization which peaks my interest. I completed the exercises and took the multiple choice quiz and received an 83% on the quiz which is okay. I learned how to manipulate searches by giving certain parameters to the search. Clauses such as: WHERE, LIKE, CASE, LIMIT, ORDER BY, etc are all used to narrow down searchs and to speed up search times. SQL is fun because I like manipulating data and seeing results. :)

**Thoughts**: Today, I did not want to read a whole chapter in my book then start to code, so I just went on codeacademy.com to quickly start coding. It is a helpful website and it makes learning new languages less daunting. Whenever I heard someone speak of SQL I was immediately intimidated but there is no reason to be. I am on this journey to learn and I can't let any mental blocks deter me from my goals. My goals are to have enough knowledge in computer programming to be employeable. I know I will be a great asset to a company someday.

### Day 4: July 1st, 2018

**Today's Progress**: Reading "How To Automate the Boring Stuff With Python". It's a great book. Today I read chapter 5 which is about dictionaries. The author had me code a tic-tac-toe game using dictionaries and it made perfect sense. The game board was a data structure and the computer knows how to interpret it because I gave it the parameters to do so. Then I coded an inventory list and printed how many total items in the inventory as well as the quantity of each item. Good day of coding so far.

**Thoughts**: I can feel myself becoming better already. It's only been four days but I've been having a fun time coding. There are still concepts I'm trying to wrap my head around like dictionaries and lists but I am a lot less perplexed with those ideas. Onward.

**Link:** https://github.com/gantgarrett/Projects/blob/master/tictactoe.py

**Link:** https://github.com/gantgarrett/Projects/blob/master/fantasygameinventory.py

### Day 5: July 2nd, 2018

**Today's Progress**: Wow, I'm dabbling with data visualization and I'm having a blast. I read data from an excel sheet and started plotting points on a graph with ease. I'm using Jupyter Notebook for all my data visualization work and so far it's so fun for me. My favorite subreddit is r/dataisbeautiful. I can't wait to start conducting my own experiments and graphing the data.

**Thoughts:** Data Analysis intrigues me. I'm going to keep practicing with Jupyter Notebook and Python because it has been so user-friendly so far. My graphs will become more in depths and pretty and it just makes me gitty thinking about it all. It's only been 5 days and I'm going to be a data expert by the end of this journey! There are no links to projects today because I was just tinkering with the software.

### Day 6: July 3rd, 2018

**Today's Progress:** This morning I played around with Seaborn. It is a Python library for making interesting looking graphs. Today I used ViolinPlot to graph heart pulse by the amount of time rest. I'm amazed on how quick and painless it is with Python to create very interesting looking graphs! I was getting stuck but I used Google and Youtube videos to figure it out (for the most part).

**Thoughts:** Python is such a powerful language. I like being able to record data and then plot points. I have always liked collecting data but now since I know how easy it is to graph data in cool new interesting ways, I literally want to record everything and graph it. More to come. No GitHub link to the project yet because I'm trying to figure out how to push Jupyter Notebook files to GitHub.

### Day 7: July 4th, 2018

**Today's Progress:** What a morning it was. I woke up around 8am and started coding around 8:30am and it is now 3:22pm and I have finially finished my little data visualization project. I went through each of 21 Savages Albums and recorded how many times he says the words, "Dick" and "Pussy" in his songs because it's like every time I hear a 21 Savage song, those words are the most reoccuring throughout! So I did a little experimenting and this is what I came up with.

**Link:** https://github.com/gantgarrett/Projects/blob/master/21SavageLyricData.ipynb

**Thoughts:** It was a blast recording this data. I realize I could be recording more valueable data but why not do this for fun?! More data viz projects to come!

### Day 8: July 5th, 2018

**Today's Progress:** Okay so I decided to mess around with more data visualization stuff. Today I struggled more. I'm trying to work with the actual Seaborn library but my graphs still just look like standard matplotlib graphs. I want my graphs more elaborate and easy to look at. I'm understanding Jupyter Notebook a lot more and now all I want to do is graph data. I have a link to the project I worked on today.

**Link:** https://github.com/gantgarrett/Projects/blob/master/LotteryGameStatistics.ipynb

**Thoughts:** I'm becoming more fluent in writing code. I'm starting to understand the syntax so much more just by analyzing other's work. And by analyzing other's work, I can manipulate my own code to work around the template of their work. It is great fun!

### Day 9: July 6th, 2018

**Today's Progress:** I was up past midnight coding so the progress I did then counts for now even though I slept. So, I'm still trying to figure out how to use my own dataframes in seaborn. I can only use the given dataframes from seaborn's github for some reason. Seaborn is not letting me import my own csv files. It's getting me frustrated. And all the tutorials I'm watching they are using Seaborn's github files too! It's like dang, how am I supposed to get my own data on there? I know how to read_csv file from the pandas library but not Seaborn. I'll figure it out though. So here is a project from Seaborn's github dataset.

**Link:** https://github.com/gantgarrett/Projects/blob/master/AirplaneStatistics.ipynb

**Thoughts:** We are living in an information-based world and it makes perfect sense to collect that information and to make visualizations for the evaluated data. It has been really intriguing for me so far. All I want to do is consume data...

### Day 10: July 7th, 2018

**Today's Progress:** I am at Nathan's new house in Venice Beach. Nathan, John, and I all were working on hackerrank.com to brush up on coding. I'm getting better but there is still so much I have to learn. I'm all aboard the coding train though. No link today.

**Thoughts:** It seems as if I'm in a mild coding rut. I need to get out of it somehow.

### Day 11: July 9th, 2018

**Today's Progress:** So I whipped up some data by playing Counter Strike: Global Offensive. I logged my kills and my deaths for each game played and graphed the results using Python and Jupyter Notebook. The data is pretty boring and uneventful. I have no clue why I even wanted to graph the kill/death ratio. I think it's because I wanted an excuse to play CS:GO and an excuse to graph data. I'm short on ideas as of late as to what I actually want to work on for my next big project. An idea will come to me though soon enough. This is only day 11.

**Link:** https://github.com/gantgarrett/Projects/blob/master/CSGOstats7-9-18.ipynb

**Thoughts:** So my coding skills have drastically increased compared to my coding skills from a couple days ago. I think I made the graph in 3 minutes as oppossed to 5+ hours with my 21 Savage lyric graph. I now need to work on a bigger more meaningful project. I need practical data to plot.

### Day 12: July 10th, 2018

**Today's Progress:** Decided to make a calculator (like I tend to do) for my statistics class. It's a Poisson Probability Calculator which asks for the mean of the rate of occurence and the number of occurences and it will produce the percentage of reaching those numbers. So, I see it working for tons of applications. Like I can calculate the probability of me getting 20 kills per game in CS:GO then graph it. I don't know, but designing calculators helps me remember the formulas so that's why I'm making them.

**Link:** https://github.com/gantgarrett/Projects/blob/master/poissonprobabilitycalc.py

**Thoughts:** I made the calculator pretty fast. I'm understanding Python a lot more. I'm proud of this calculator but it has been made many times before. At this point I'm just brushing and practicing for the next big project.

### Day 13: July 11th, 2018

**Today's Progress:** Not much coding was done today. Being a student and not having a laptop makes it hard to actually work on practical projects while on the go. I need to invest in a laptop. Anyway, I'm reading all about web scraping. My next project will be a web scraping project looking into a certain dataset. The program will scrape the website and return valuable information from it. I then plan on using the info to plot graphs.

**Thoughts:** Even though I didn't do coding as much as I would have liked to today, the project ideas are what counts.

### Day 14: July 12th, 2018

**Today's Progress:** Been viciously busy with school so it was hard finding time to code. I Twitter account though to hold myself accountable for 100 Days of Code. I would like to think making a Twitter Bot that retweets and favorites other tweets is code but it was hardly code at all, still code none-the-less. I also worked on some JavaScript which resembles C++ to me. I'm going to work on more data viz stuff with Python tomorrow morning.

**Thoughts:** So far so good with this challenge. I'mm learning so much and involving myself with such a supportive community. Coding's great!

### Day 15: July 13, 2018

**Today's Progress:** Started to parse through the chessgames.csv. I'm trying to find a correlation between the opening ecosystem and who wins. But I'm having trouble because when I parse through a certain parameter, I cannot parse through the newly created dataset. For instance, the opening ecosystem is D10, it gives me a new dataset with only D10 as the ecosystem. How can I take this new dataset and parse through it to see who won? That is what I'm having trouble with. I got my 1 hour+ in today. In the mean time, I'm playing two shows tonight with my band, so maybe I can collect some data then. Like how many people are at each show? Then graph the results. It could be cool!

**Thoughts:** I have to keep reminding myself to not get frustrated. Coding is hard. I'm just now diving in very deep now so I need to be patient with myself and were I'm at as a programmer. I know there is greatness right around the corner. I need to be persistent and diligent with my work and try my best. But now I have to get ready to rehearse with my band. We're covering Black Flag sooooo.

### Day 16: July 14th, 2018

**Today's Progress:** I had my friends help me get a head count at each one of my band's gigs. My band played two shows in one night on 7/13/18. I wanted to collect data on why people attend. The house show had more people there because there was drugs and alcohol involved. The venue we played at does not allow for drugs or alcohol so there were 24 people there. The crowd reaction at the house show was cool but the venue was much more intimate and we met some cool bands that are from out of the country! Needless to say, last night was great fun. To me, it doesn't matter if 1 person is watching our set or 100, at least we are playing music. Here is the graph:

**Link:** https://github.com/gantgarrett/Projects/blob/master/RECLAIM.ipynb

**Thoughts:** I had some trouble initially trying to graph this thing. I now know you don't always need to read from a .csv file. If the dataset is small enough, you can just input the numbers yourself. I like being able to collect data even if it's something small like this... we are able to visualize correlations for sure!

### Day 17: July 15th, 2018

**Today's Progress:** I was curious about Disney World's ticket price increase over the years (just to graph something...). The graph showed an exponential increase. I want to add another line showing the cost of living compared to the ticket prices increasing. It should show interesting results. I also want to make more diverse graphs. I need more interesting data to collect!

**Thoughts:** I plan on adding the second line to the graph tomorrow morning. Correlation between cost of living and ticket increase? I think so! Right now I'm beat because I just drove with Kameron to LAX to pick up his parents from the airport. I finished that graph on his laptop on the car ride down though. It was fun!

### Day 18: July 16th, 2018

**Today's Progress:** Woke up at 5:30am and started coding at 6:00am. I gathered more data for my graph. I graphed minimum wage and 2017 inflation prices on the cost of tickets from 1971 to 2017. I don't know it was just an idea in my head. Now it has been graphed and it's visually easy to look at. The ticket prices have gone up so exponentially compared to minimum wage, it's very interesting to look at. That means Disney World is doing well to keep prices rising each year. Intriguing data indeed.

**Link:** https://github.com/gantgarrett/Projects/blob/master/disneyworldstats.ipynb

**Thoughts:** This is fun and all but not technically challenging. It is fun to collect data and graph it using Python but I'm wanting to build some tools now. Practical applications. Trying to figure that one out though.

### Day 19: July 17th, 2018

**Today's Progress:** Woke up at 6:00am and started coding around 6:45am. It is now 8:25am and I successfully understand web scraping. I watched a tutorial video and followed along with instructions and I parsed through graphics cards on newegg.com and then wrote the results on a .csv file. Then with the .csv file I can graph the results and much more. Python is such a powerful tool. I'm having fun webscraping, the whole internet is now my database!

**Thoughts:** I accidentally erased the damn script so I'm going to have to practice on other websites now. It isn't hard at all, just looking through HTML text and then you have to use the Python to specify what you want to find. Make a for loop and... BANG! Website scraped! I would post it to my github but like I said it has been erased... Continuing to webscrape though for sure. Data collection can be so fast and seemless.

### Day 20: July 18th, 2018

**Today's Progress:** Started more web scraping. Was going to webscrape a comic book store website but it seems kind of useless. I am understanding the concept of webscraping more thoroughly though. It's just a really efficient way of parsing through data that you would like to put into an even more organized format.

**Thoughts:** Going to work on more web scraping tomorrow.

### Day 21: July 19th, 2018

**Today's Progress:** Yooooooooooo, finished my first web scraper! I'm pretty pumped. I went through some struggles but I eventually figured it out. It was fun parsing through HTML and extracting data. A script will automatically get everything updated too. The webpage of course does not have every single comic book release on one page so I need to figure out how to tell the script to search other pages as well.

**Link:** https://github.com/gantgarrett/Projects/blob/master/comixwebscraper.py

**Thoughts:** This is so great. I had no idea I had this potential to do this and with relative ease! I'm excited to see where it takes me!

### Day 22: July 23rd, 2018

**Today's Progress:** So it has been a wonderful weekend. I got a break from coding and school and visited my friend Nathan in Venice with my companion and lover, Jackie. I do all of my projects on my PC at home so I had literally no access to my computer. But it is okay to go out and party every now and again! I tried making an eBay webscraper but could not figure out how to loop through each container on the page. The page is divided into containers of 24 and the first 24 containers of items are the only items that are being picked up and not the whole page of 100 items. Something I will have to figure out to negate.

**Thoughts:** I will continue more webscraping exercises later.

### Day 23: July 24th, 2018

**Today's Progress:** Understanding the R language a lot better. Watched a tutorial video on the subject and I am able to figure out the commands and syntax with relative ease. Looking at code has become so much easier. I'm exposing myself to as many languages as I can because it does not hurt to be diverse, like at all. As of right now though, I'm sort of in a coder's block. I have many projects cycling through my head it's just being able to expell them now. I need to focus on one thing generally. Data Viz is right up my alley though so I would like to continue to practice with R.

**Thoughts:** Okay, I'm going to dedicate some more time to learning R but as of right now, I still have school to go to today, I'm trying to move out of my mom's house, I'm actively looking for a job, and I'm working on becoming a better person who is less anxious and quiet. I don't like being anxious or quiet.

### Day 24: July 25th, 2018

**Today's Progress:** Graphed some more data using R. I'm getting stuck with making actual correletions. I need to watch more tutorial videos.

**Link:** https://twitter.com/Garrtacular7/status/1022259701256310784

**Thoughts:** Trying to just come up with projects my dude.

### Day 25: July 26th, 2018

**Today's Progress:** R is easier than I thought. The code is so easy to add layers. You literally just use a + sign to add any additional layer. I've downloaded data sets from Kaggle now I just need to put them to good use. I tried seeing a correlation between raising your hand in class and if you go to discussion meets... lol looked like no correlation at all. But I did see a correlation that if the student raises their hand, the parent's schools happiness is better. I'm going to continue my studies in this field. It is very interesting.

**Link:** https://twitter.com/Garrtacular7/status/1022500989775953920

**Thoughts:** R is easier than Python to graph but Python is easier to extract certain parts of the data that you need. I don't think R has parameter functions to parse through certain cells in the data set. I may be wrong. The graphs in R look more professional though as oppossed the Python graphs in matplotlib. I need to figure out how to graph ill ass sets though. Violin plot my homie...

### Day 26: July 27th, 2018

**Today's Progress:** Listened to the Data Scientist Podcast and I loved it. It got me start reading R for Data Science and it is a really helpful book so far. I graphed their sample data set of mpg. 

**Thoughts:** More R, more R, more R.

### Day 27: July 28th, 2018

**Today's Progress:** I scavenged the internet for data sets that I can mess around with. I choose NASA because I love space. Their was a data set about the landings of meteorites so I decided to graph the year vs the mass. It's not a huge correlation between the two but it was interesting to see that only a few cases were the outliers. 

**Link:** https://twitter.com/Garrtacular7/status/1023316614924525568

**Thoughts:** I'm loving R. I just need to mess around with it more and collect more valuable data.

### Day 28: July 29th, 2018

**Today's Progress:** I need to study data more. I understand how to come across the correlations, it's just being able to code and graph the correlations now. I keep getting errors and can't wrap my head around certain concepts in R quite yet. It's so fun going through different data sets and graphing them. I love data viz. Today, I was having coders block so I couldn't figure out what to make but I ended up just graphing if there's a correlation between raising your hand in class and then visiting outside resources. Not much of a correlation and sort of uninteresting data but hey it worked.

**Link:** https://twitter.com/Garrtacular7/status/1023615480949403648

**Thoughts:** I'm going to have to take my R skills to the next level but I'm content with where I am now compared to where I was a week ago which was no where... lol.

### Day 29: July 30th, 2018

**Today's Progress:** Web scraping Youtube.

**Thoughts:** Working on a webscraper for Youtube.

### Day 30: July 31st, 2018

**Today's Progress:** Continued to work on the Youtube webscraper to scrape every hour the live view count of lofi hip hop radio. LOL I think it's such a fun idea. I just need to extract the live view count in the python script and boom... hella graphable data. It's just a fun project but then I can start making correlations by time of day and day of the week and all that good stuff.

**Thoughts:** Diving deeper into Python and webscraping. It is a lot of fun but frustrating when I'm not getting direct results. There is seriously only one element I need to extract and I'm having trouble with that. Will work on it later though.

### Day 31: August 1st, 2018

**Today's Progress:** Could not figure out how to make the Youtube scraper. I think they have already thought of people trying to scrape their website so they put blocks on it or something. So then I moved on to Twitch to see if I could actively scrape the viewship of the top games. Could not scrape the containers and that is seriously all I need! Then I tried going to newegg and scraping their website for graphics cards and boom! It works but I have already done that! It also worked on the comic book site too but not the big name website for some reason. I'm getting hella annoyed because I know how to scrape but the website or something is blocking me from doing it.

**Thoughts:** I will continue to web scrape but I want valueble info scraped. There are plenty of websites I can scrape though. I just need to find something interesting. I haven't posted a project on github in a cool minute and that needs to change. I just haven't been able to complete any projects lately. :( There's been blockages.
