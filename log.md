# 100 Days Of Code - Log

### Day 1: June 28th, 2018

**Today's Progress**: Tried out FreeCodeCamp.org, got bored and started dabbling with Python. Fiddling around with mean, median and mode functions that are part of the Python library. I'm doing so becaue I am currently taking statistics.

**Thoughts:** I struggled with remembering syntax of Python but nothing a little Google searching couldn't do.
**Link:** https://github.com/gantgarrett/Projects/blob/master/meanmedianmode.py


### Day 2: June 29th, 2018

**Today's Progress**: Currently reading "Automate the Boring Stuff With Python" to understand the Python language better. I am understanding the language but there are concepts I'm still trying to wrap my head around like nested for loops and being able to manipulate lists and tuples. The author includes coding exercises after each chapter so I attempt them but I end up not finding my answer in the book so I do some Google searching to see what others have done. It helps bring context to the exercises. It feels like I spoil the fun of figuring out the programs myself but there's no way I could come up with the code myself quite yet... yet.

**Thoughts**: Python is flexible and easy to read compared to most languages I have worked with. If I keep practicing (which is why I'm donig 100-days-of-code) I know I will become fluent in the language.

### Day 3: June 30th, 2018

**Today's Progress**: I went on codeacademy.com to work on SQL. I find SQL interesting because it is database organization which peaks my interest. I completed the exercises and took the multiple choice quiz and received an 83% on the quiz which is okay. I learned how to manipulate searches by giving certain parameters to the search. Clauses such as: WHERE, LIKE, CASE, LIMIT, ORDER BY, etc are all used to narrow down searchs and to speed up search times. SQL is fun because I like manipulating data and seeing results. :)

**Thoughts**: Today, I did not want to read a whole chapter in my book then start to code, so I just went on codeacademy.com to quickly start coding. It is a helpful website and it makes learning new languages less daunting. Whenever I heard someone speak of SQL I was immediately intimidated but there is no reason to be. I am on this journey to learn and I can't let any mental blocks deter me from my goals. My goals are to have enough knowledge in computer programming to be employeable. I know I will be a great asset to a company someday.

### Day 4: July 1st, 2018

**Today's Progress**: Reading "How To Automate the Boring Stuff With Python". It's a great book. Today I read chapter 5 which is about dictionaries. The author had me code a tic-tac-toe game using dictionaries and it made perfect sense. The game board was a data structure and the computer knows how to interpret it because I gave it the parameters to do so. Then I coded an inventory list and printed how many total items in the inventory as well as the quantity of each item. Good day of coding so far.

**Thoughts**: I can feel myself becoming better already. It's only been four days but I've been having a fun time coding. There are still concepts I'm trying to wrap my head around like dictionaries and lists but I am a lot less perplexed with those ideas. Onward.

**Link:** https://github.com/gantgarrett/Projects/blob/master/tictactoe.py

**Link:** https://github.com/gantgarrett/Projects/blob/master/fantasygameinventory.py

### Day 5: July 2nd, 2018

**Today's Progress**: Wow, I'm dabbling with data visualization and I'm having a blast. I read data from an excel sheet and started plotting points on a graph with ease. I'm using Jupyter Notebook for all my data visualization work and so far it's so fun for me. My favorite subreddit is r/dataisbeautiful. I can't wait to start conducting my own experiments and graphing the data.

**Thoughts:** Data Analysis intrigues me. I'm going to keep practicing with Jupyter Notebook and Python because it has been so user-friendly so far. My graphs will become more in depths and pretty and it just makes me gitty thinking about it all. It's only been 5 days and I'm going to be a data expert by the end of this journey! There are no links to projects today because I was just tinkering with the software.

### Day 6: July 3rd, 2018

**Today's Progress:** This morning I played around with Seaborn. It is a Python library for making interesting looking graphs. Today I used ViolinPlot to graph heart pulse by the amount of time rest. I'm amazed on how quick and painless it is with Python to create very interesting looking graphs! I was getting stuck but I used Google and Youtube videos to figure it out (for the most part).

**Thoughts:** Python is such a powerful language. I like being able to record data and then plot points. I have always liked collecting data but now since I know how easy it is to graph data in cool new interesting ways, I literally want to record everything and graph it. More to come. No GitHub link to the project yet because I'm trying to figure out how to push Jupyter Notebook files to GitHub.

### Day 7: July 4th, 2018

**Today's Progress:** What a morning it was. I woke up around 8am and started coding around 8:30am and it is now 3:22pm and I have finially finished my little data visualization project. I went through each of 21 Savages Albums and recorded how many times he says the words, "Dick" and "Pussy" in his songs because it's like every time I hear a 21 Savage song, those words are the most reoccuring throughout! So I did a little experimenting and this is what I came up with.

**Link:** https://github.com/gantgarrett/Projects/blob/master/21SavageLyricData.ipynb

**Thoughts:** It was a blast recording this data. I realize I could be recording more valueable data but why not do this for fun?! More data viz projects to come!

### Day 8: July 5th, 2018

**Today's Progress:** Okay so I decided to mess around with more data visualization stuff. Today I struggled more. I'm trying to work with the actual Seaborn library but my graphs still just look like standard matplotlib graphs. I want my graphs more elaborate and easy to look at. I'm understanding Jupyter Notebook a lot more and now all I want to do is graph data. I have a link to the project I worked on today.

**Link:** https://github.com/gantgarrett/Projects/blob/master/LotteryGameStatistics.ipynb

**Thoughts:** I'm becoming more fluent in writing code. I'm starting to understand the syntax so much more just by analyzing other's work. And by analyzing other's work, I can manipulate my own code to work around the template of their work. It is great fun!

### Day 9: July 6th, 2018

**Today's Progress:** I was up past midnight coding so the progress I did then counts for now even though I slept. So, I'm still trying to figure out how to use my own dataframes in seaborn. I can only use the given dataframes from seaborn's github for some reason. Seaborn is not letting me import my own csv files. It's getting me frustrated. And all the tutorials I'm watching they are using Seaborn's github files too! It's like dang, how am I supposed to get my own data on there? I know how to read_csv file from the pandas library but not Seaborn. I'll figure it out though. So here is a project from Seaborn's github dataset.

**Link:** https://github.com/gantgarrett/Projects/blob/master/AirplaneStatistics.ipynb

**Thoughts:** We are living in an information-based world and it makes perfect sense to collect that information and to make visualizations for the evaluated data. It has been really intriguing for me so far. All I want to do is consume data...

### Day 10: July 7th, 2018

**Today's Progress:** I am at Nathan's new house in Venice Beach. Nathan, John, and I all were working on hackerrank.com to brush up on coding. I'm getting better but there is still so much I have to learn. I'm all aboard the coding train though. No link today.

**Thoughts:** It seems as if I'm in a mild coding rut. I need to get out of it somehow.

### Day 11: July 9th, 2018

**Today's Progress:** So I whipped up some data by playing Counter Strike: Global Offensive. I logged my kills and my deaths for each game played and graphed the results using Python and Jupyter Notebook. The data is pretty boring and uneventful. I have no clue why I even wanted to graph the kill/death ratio. I think it's because I wanted an excuse to play CS:GO and an excuse to graph data. I'm short on ideas as of late as to what I actually want to work on for my next big project. An idea will come to me though soon enough. This is only day 11.

**Link:** https://github.com/gantgarrett/Projects/blob/master/CSGOstats7-9-18.ipynb

**Thoughts:** So my coding skills have drastically increased compared to my coding skills from a couple days ago. I think I made the graph in 3 minutes as oppossed to 5+ hours with my 21 Savage lyric graph. I now need to work on a bigger more meaningful project. I need practical data to plot.

### Day 12: July 10th, 2018

**Today's Progress:** Decided to make a calculator (like I tend to do) for my statistics class. It's a Poisson Probability Calculator which asks for the mean of the rate of occurence and the number of occurences and it will produce the percentage of reaching those numbers. So, I see it working for tons of applications. Like I can calculate the probability of me getting 20 kills per game in CS:GO then graph it. I don't know, but designing calculators helps me remember the formulas so that's why I'm making them.

**Link:** https://github.com/gantgarrett/Projects/blob/master/poissonprobabilitycalc.py

**Thoughts:** I made the calculator pretty fast. I'm understanding Python a lot more. I'm proud of this calculator but it has been made many times before. At this point I'm just brushing and practicing for the next big project.

### Day 13: July 11th, 2018

**Today's Progress:** Not much coding was done today. Being a student and not having a laptop makes it hard to actually work on practical projects while on the go. I need to invest in a laptop. Anyway, I'm reading all about web scraping. My next project will be a web scraping project looking into a certain dataset. The program will scrape the website and return valuable information from it. I then plan on using the info to plot graphs.

**Thoughts:** Even though I didn't do coding as much as I would have liked to today, the project ideas are what counts.

### Day 14: July 12th, 2018

**Today's Progress:** Been viciously busy with school so it was hard finding time to code. I Twitter account though to hold myself accountable for 100 Days of Code. I would like to think making a Twitter Bot that retweets and favorites other tweets is code but it was hardly code at all, still code none-the-less. I also worked on some JavaScript which resembles C++ to me. I'm going to work on more data viz stuff with Python tomorrow morning.

**Thoughts:** So far so good with this challenge. I'mm learning so much and involving myself with such a supportive community. Coding's great!

### Day 15: July 13, 2018

**Today's Progress:** Started to parse through the chessgames.csv. I'm trying to find a correlation between the opening ecosystem and who wins. But I'm having trouble because when I parse through a certain parameter, I cannot parse through the newly created dataset. For instance, the opening ecosystem is D10, it gives me a new dataset with only D10 as the ecosystem. How can I take this new dataset and parse through it to see who won? That is what I'm having trouble with. I got my 1 hour+ in today. In the mean time, I'm playing two shows tonight with my band, so maybe I can collect some data then. Like how many people are at each show? Then graph the results. It could be cool!

**Thoughts:** I have to keep reminding myself to not get frustrated. Coding is hard. I'm just now diving in very deep now so I need to be patient with myself and were I'm at as a programmer. I know there is greatness right around the corner. I need to be persistent and diligent with my work and try my best. But now I have to get ready to rehearse with my band. We're covering Black Flag sooooo.

### Day 16: July 14th, 2018

**Today's Progress:** I had my friends help me get a head count at each one of my band's gigs. My band played two shows in one night on 7/13/18. I wanted to collect data on why people attend. The house show had more people there because there was drugs and alcohol involved. The venue we played at does not allow for drugs or alcohol so there were 24 people there. The crowd reaction at the house show was cool but the venue was much more intimate and we met some cool bands that are from out of the country! Needless to say, last night was great fun. To me, it doesn't matter if 1 person is watching our set or 100, at least we are playing music. Here is the graph:

**Link:** https://github.com/gantgarrett/Projects/blob/master/RECLAIM.ipynb

**Thoughts:** I had some trouble initially trying to graph this thing. I now know you don't always need to read from a .csv file. If the dataset is small enough, you can just input the numbers yourself. I like being able to collect data even if it's something small like this... we are able to visualize correlations for sure!

### Day 17: July 15th, 2018

**Today's Progress:** I was curious about Disney World's ticket price increase over the years (just to graph something...). The graph showed an exponential increase. I want to add another line showing the cost of living compared to the ticket prices increasing. It should show interesting results. I also want to make more diverse graphs. I need more interesting data to collect!

**Thoughts:** I plan on adding the second line to the graph tomorrow morning. Correlation between cost of living and ticket increase? I think so! Right now I'm beat because I just drove with Kameron to LAX to pick up his parents from the airport. I finished that graph on his laptop on the car ride down though. It was fun!

### Day 18: July 16th, 2018

**Today's Progress:** Woke up at 5:30am and started coding at 6:00am. I gathered more data for my graph. I graphed minimum wage and 2017 inflation prices on the cost of tickets from 1971 to 2017. I don't know it was just an idea in my head. Now it has been graphed and it's visually easy to look at. The ticket prices have gone up so exponentially compared to minimum wage, it's very interesting to look at. That means Disney World is doing well to keep prices rising each year. Intriguing data indeed.

**Link:** https://github.com/gantgarrett/Projects/blob/master/disneyworldstats.ipynb

**Thoughts:** This is fun and all but not technically challenging. It is fun to collect data and graph it using Python but I'm wanting to build some tools now. Practical applications. Trying to figure that one out though.

### Day 19: July 17th, 2018

**Today's Progress:** Woke up at 6:00am and started coding around 6:45am. It is now 8:25am and I successfully understand web scraping. I watched a tutorial video and followed along with instructions and I parsed through graphics cards on newegg.com and then wrote the results on a .csv file. Then with the .csv file I can graph the results and much more. Python is such a powerful tool. I'm having fun webscraping, the whole internet is now my database!

**Thoughts:** I accidentally erased the damn script so I'm going to have to practice on other websites now. It isn't hard at all, just looking through HTML text and then you have to use the Python to specify what you want to find. Make a for loop and... BANG! Website scraped! I would post it to my github but like I said it has been erased... Continuing to webscrape though for sure. Data collection can be so fast and seemless.

### Day 20: July 18th, 2018

**Today's Progress:** Started more web scraping. Was going to webscrape a comic book store website but it seems kind of useless. I am understanding the concept of webscraping more thoroughly though. It's just a really efficient way of parsing through data that you would like to put into an even more organized format.

**Thoughts:** Going to work on more web scraping tomorrow.

### Day 21: July 19th, 2018

**Today's Progress:** Yooooooooooo, finished my first web scraper! I'm pretty pumped. I went through some struggles but I eventually figured it out. It was fun parsing through HTML and extracting data. A script will automatically get everything updated too. The webpage of course does not have every single comic book release on one page so I need to figure out how to tell the script to search other pages as well.

**Link:** https://github.com/gantgarrett/Projects/blob/master/comixwebscraper.py

**Thoughts:** This is so great. I had no idea I had this potential to do this and with relative ease! I'm excited to see where it takes me!

### Day 22: July 23rd, 2018

**Today's Progress:** So it has been a wonderful weekend. I got a break from coding and school and visited my friend Nathan in Venice with my companion and lover, Jackie. I do all of my projects on my PC at home so I had literally no access to my computer. But it is okay to go out and party every now and again! I tried making an eBay webscraper but could not figure out how to loop through each container on the page. The page is divided into containers of 24 and the first 24 containers of items are the only items that are being picked up and not the whole page of 100 items. Something I will have to figure out to negate.

**Thoughts:** I will continue more webscraping exercises later.

### Day 23: July 24th, 2018

**Today's Progress:** Understanding the R language a lot better. Watched a tutorial video on the subject and I am able to figure out the commands and syntax with relative ease. Looking at code has become so much easier. I'm exposing myself to as many languages as I can because it does not hurt to be diverse, like at all. As of right now though, I'm sort of in a coder's block. I have many projects cycling through my head it's just being able to expell them now. I need to focus on one thing generally. Data Viz is right up my alley though so I would like to continue to practice with R.

**Thoughts:** Okay, I'm going to dedicate some more time to learning R but as of right now, I still have school to go to today, I'm trying to move out of my mom's house, I'm actively looking for a job, and I'm working on becoming a better person who is less anxious and quiet. I don't like being anxious or quiet.

### Day 24: July 25th, 2018

**Today's Progress:** Graphed some more data using R. I'm getting stuck with making actual correletions. I need to watch more tutorial videos.

**Link:** https://twitter.com/Garrtacular7/status/1022259701256310784

**Thoughts:** Trying to just come up with projects my dude.

### Day 25: July 26th, 2018

**Today's Progress:** R is easier than I thought. The code is so easy to add layers. You literally just use a + sign to add any additional layer. I've downloaded data sets from Kaggle now I just need to put them to good use. I tried seeing a correlation between raising your hand in class and if you go to discussion meets... lol looked like no correlation at all. But I did see a correlation that if the student raises their hand, the parent's schools happiness is better. I'm going to continue my studies in this field. It is very interesting.

**Link:** https://twitter.com/Garrtacular7/status/1022500989775953920

**Thoughts:** R is easier than Python to graph but Python is easier to extract certain parts of the data that you need. I don't think R has parameter functions to parse through certain cells in the data set. I may be wrong. The graphs in R look more professional though as oppossed the Python graphs in matplotlib. I need to figure out how to graph ill ass sets though. Violin plot my homie...

### Day 26: July 27th, 2018

**Today's Progress:** Listened to the Data Scientist Podcast and I loved it. It got me start reading R for Data Science and it is a really helpful book so far. I graphed their sample data set of mpg. 

**Thoughts:** More R, more R, more R.

### Day 27: July 28th, 2018

**Today's Progress:** I scavenged the internet for data sets that I can mess around with. I choose NASA because I love space. Their was a data set about the landings of meteorites so I decided to graph the year vs the mass. It's not a huge correlation between the two but it was interesting to see that only a few cases were the outliers. 

**Link:** https://twitter.com/Garrtacular7/status/1023316614924525568

**Thoughts:** I'm loving R. I just need to mess around with it more and collect more valuable data.

### Day 28: July 29th, 2018

**Today's Progress:** I need to study data more. I understand how to come across the correlations, it's just being able to code and graph the correlations now. I keep getting errors and can't wrap my head around certain concepts in R quite yet. It's so fun going through different data sets and graphing them. I love data viz. Today, I was having coders block so I couldn't figure out what to make but I ended up just graphing if there's a correlation between raising your hand in class and then visiting outside resources. Not much of a correlation and sort of uninteresting data but hey it worked.

**Link:** https://twitter.com/Garrtacular7/status/1023615480949403648

**Thoughts:** I'm going to have to take my R skills to the next level but I'm content with where I am now compared to where I was a week ago which was no where... lol.

### Day 29: July 30th, 2018

**Today's Progress:** Web scraping Youtube.

**Thoughts:** Working on a webscraper for Youtube.

### Day 30: July 31st, 2018

**Today's Progress:** Continued to work on the Youtube webscraper to scrape every hour the live view count of lofi hip hop radio. LOL I think it's such a fun idea. I just need to extract the live view count in the python script and boom... hella graphable data. It's just a fun project but then I can start making correlations by time of day and day of the week and all that good stuff.

**Thoughts:** Diving deeper into Python and webscraping. It is a lot of fun but frustrating when I'm not getting direct results. There is seriously only one element I need to extract and I'm having trouble with that. Will work on it later though.

### Day 31: August 1st, 2018

**Today's Progress:** Could not figure out how to make the Youtube scraper. I think they have already thought of people trying to scrape their website so they put blocks on it or something. So then I moved on to Twitch to see if I could actively scrape the viewship of the top games. Could not scrape the containers and that is seriously all I need! Then I tried going to newegg and scraping their website for graphics cards and boom! It works but I have already done that! It also worked on the comic book site too but not the big name website for some reason. I'm getting hella annoyed because I know how to scrape but the website or something is blocking me from doing it.

**Thoughts:** I will continue to web scrape but I want valueble info scraped. There are plenty of websites I can scrape though. I just need to find something interesting. I haven't posted a project on github in a cool minute and that needs to change. I just haven't been able to complete any projects lately. :( There's been blockages.

### Day 32: August 2nd, 2018

**Today's Progress:** Finished the newegg webscraper. I'm very familiar with how to scrape now. It is not hard at all, it's just telling the Python script what to look for. It's actually a lot of fun when it starts working. Now, gather data on the standard deviation of price drops throughout the week would be interesting!

**Link:** https://github.com/gantgarrett/Projects/blob/master/neweggwebscraper.py

**Link:** https://twitter.com/Garrtacular7/status/1025227404481114114

**Thoughts:** I have many more plans on webscraping. This has just been practice but I am able to understand it very quickly. I know how to analyze HTML but I don't know how to write it. I'm more interested in collecting data and parsing it anyway than making websites, although I know I can make a website easily. So far Python has not let me down with its very flexible design! More Python to come homies.

### Day 33: August 3rd, 2018

**Today's Progress:** So I'm watching Mission Impossible 6 with my grandpa today, so naturally I wanted to web scrape. I went on imdb.com to see user reviews and the title of the review. I scraped both. It took me 15 minutes. I have gotten more fluent in it with practice. I took the data, wrote it to a .csv file and then made a correlation to the reviews. There are more 10 star reviews than anything and it's a sample statistics as well. It was a cool little project if I say so myself!

**Link:** https://github.com/gantgarrett/Projects/blob/master/mi6scraper.py

**Link:** https://twitter.com/Garrtacular7/status/1025439964706758656

**Thoughts:** Web scraping is so fun for me and I don't know why. Maybe because I get to extract data that I want while giving the computer commands to do so. I feel like I have power! Python is my favorite language for sure! I like coming up with these little projects, it gives me worth and something to do.

### Day 34: August 4th, 2018

**Today's Progress:** I'm going to become a data scientist. It is my calling. I can feel it. I've done a lot of studying today on the subject and I have been practicing with R and Python recently. I woke up wanting to build a website with Django but then when I launched it there was a bunch of compilation errors and I was like nooooooo. So I gave up on that and now I'm diving deep into what it takes to become a data scientist. It's about asking the right questions in terms of data sets, making correlations, tidying up the data, transforming the data, visualizing the data, modeling the data and then finally communicating the data. I need to study and finish my degree so I will be more valuable to a company. It is difficult but I know when my momentum starts building, there is no stopping me. I have learned a lot in these short hours.

**Thoughts:** On the road to become a data scientist and I will have what it takes!

### Day 35: August 6th, 2018

**Today's Progress:** Not very happy with myself that I missed yesterday's coding session. We had a small family renunion so it's understandable and plus it was Sunday. So, I decided to give the Introduction to Statistical Learning another read and I am glad I did. At the end of the chapters there are labs that you can work on and I finished Chapter 2 lab today. It was fun parsing through data and making correlations. It's easier understanding the logic around tidying up data now. I'm eager to learn more!

**Link:** Here is what I made: https://twitter.com/Garrtacular7/status/1026597244093386757

**Thoughts:** Diving deep and trying to get ahead of people. I have the advantage.

### Day 36: August 7th, 2018

**Today's Progress:** Parsed through data sets of TSA Claims and am trying to make correlations between Airline Names and who has the best dispositon. It is for the reddit r/dataisbeautiful challenge. It is fun so far.

**Thoughts:** Need to learn how to parse through data more efficiently and when I am able to do that, I will be golden.

### Day 37: August 14th, 2018

**Today's Progress:** So it's been a week since I've done any coding. I went to DefCon in Las Vegas and that is why I have not done any coding. I don't own a laptop so nothing could have been done. DefCon was a great experience and I am totally going next year.

**Thoughts:** I need to get back on the grind of things. It's almost as if I have lost motivation but I need to be persistent and consistent with my work. No pain no gain.

### Day 38: August 15th, 2018

**Today's Progress:** I think my main focus needs to be R. Or anything relating to data science because that will take me very very far. I know exactly what I need to extract out of the data, it's just being able to extract it and using effective visualizations.

**Thoughts:** I'm continuing to work on the TSA Claims data. I need to merge all of the data sets from Homeland Security website and find which airline has the best approval rating over the years. I wish I had nerdy friends who were into data science as well so I can have some help but I am alone on my computer trying to figure out ways to build up my portfolio. I also lost my glasses and I have no idea where they are and I'm blind so it's hard looking at the computer screen.

### Day 39: August 16th, 2018

**Today's Progress:** Been sort of at a stand still. I need to narrow my focus on a certain subject and practice with that. I know that web scraping and data science go hand in hand so if I can become more efficient at webscraping, I'll be golden. To collect data on a variety of different subjects. Python, webscraping, data visualization with either R or Tableau.

**Thoughts:** Eventually I need to design a personal website to show off my skills. There are just so many tools to build a website that I don't even know which one to use. For now, like I said I just have to focus on Python, webscraping and the data visualization of those scrapes.

### Day 40: August 17th, 2018

**Today's Progress:** Currently reading "Web Scraping with Python" hopefully I can find some useful information in there. There was an example of in the book of some back in 2006 who scraped the web of people posting about "I Feel (fill in the blank)" so the person scraped the whole web somehow and found out generally what people were feeling on the Internet. Genious! I want to conduct an experiment like that. But I need to learn to scrape the entire web... It seems right up my alley though. I would be a valueble asset to a company if I know how to effectively scrape the web. I would save so much time.

**Thoughts:** Am I getting better? I would have to think yes. Even though I took a week break and life and its struggles are bringing me down, I need to focus and stay strong. It feels as if there's crap just piling up but I need to indulge myself in my work and not stray from the path. I love coding and I want to make it a career so it is up to me to see where I can take it. I cannot give up. 4/10 of the way there!

### Day 41: August 18th, 2018

**Today's Progress:** I'm literally stuck. I do not know a viable project to conduct. Should I make a website? Should I continue to scrape websites? I want to scrape Youtube for the live view count of lofi hip hop but I do not have access to it. I want to be able to consistently graph the fluctuation of the view count. It would be interesting (at least for me to see). I'm actually getting frustrated with my coding performance lately. I need to focus my energy towards a goal. I'm having trouble finding a certain goal to work towards though. I have ideas but being able to unleash them upon the world is a different story. I'm sticking with data science and webscraping because it is fun but I have not found the information needed to perform such webscrapes on Youtube on websites with Javascript. I haven't made a project in a while either. I think I'm going to go on a walk.

**Thoughts:** I cannot let my frustration overcome by performance. I know I am destined for greatness but it's like I'm in a rut right now. I don't know what to work towards, I mean I do but it reading up on the information to do so. I will continue my studies today and see where I can go. I need motivation, it gets lonely sitting here behind my computer screen with no one else coding with me. I wish I had more friends who were into coding so I can learn from others too and not just Youtube videos.

### Day 42: August 19th, 2018

**Today's Progress:** Okay so I'm getting better. I'm scraping music websites for discographies and the likes. I went on this website called Analog Worship and they have such a scrapable site lol. Full of useful data. I want to scrape the prices on every item they have and make a histogram of where their prices lie between. I want to do this to multiple music retail sites. It's fun for me. I just need to figure out how to parse through a web page that uses the infinite scroll mechanism and tell my scraper to go to the next page. It should not be too hard and I think I need to use Selenium.

**Thoughts: I made a small scraper yesterday that scraped all of Triple-B Record discography. It was fun and it only took my like 5 minutes. Here is the link:

**Link:** https://github.com/gantgarrett/Projects/blob/master/tripleBrecordsdiscography.py

### Day 43: August 20th, 2018

**Today's Progress:** Worked really hard today and I still haven't figured out how to download pictures from a website. I understand the concept and I tried so many different attempts yet to no avail the images were not downloading. That is my goal is to figure out how to scrape all of the images off of a website because that would be fun. And scraping Analog Worship's images would be fun because I will get to see some dark underground album artwork and that's all I want. I'm trying to collect data here with scripts and automation and not trying to waste time. Building the scripts takes more time than extracting the data in an old school way but when I become more fluent, the skills I am developing will be critical in any work force. I will have the upper hand.

**Thoughts:** Web scraping is still underway. I haven't graphed anything lately which concerns me and I haven't built a massive project yet. I have to give myself more credit though for showing up to code every day and continue all of my self studying, diving into the subjects that school will not teach you.

### Day 44: August 21st, 2018

**Today's Progress:** Thoroughly coming to a close on my small little project that's taking me a while to figure out. I'm currently scraping analogworship.com in hopes to download all of their image files. I'm reading "Automate the Boring Stuff With Python" and manipulating code from the author's take on scraping images off of the web. It's interesting I want to figure out how to do this because it could be very value information I can extract.

**Thoughts:** This is fun I can't wait to finally finish it. I'm learning a lot just from this exercise alone.

### Day 45: August 22nd, 2018

**Today's Progress:** Okay, I haven't finished my project and it's discouraging me. How the heck am I supposed to scrape all the images off the website. I have looked up countless videos and articles on how to do this and I'm getting so close! It may be because of the bandwidth that I'm not able to download all of the images but I doubt it. I just want all of those album covers so badly. On the bright side I automated a scroll down button that scrolls down to the bottom of the page really fast since the website is large. I'm making slow but incremental progress for sure. But at the same time, sort of getting frustrated I can't complete this.

**Thoughts:** This is only for one website too. But I figure my problem is somewhere in the while loop or that I need to create a for loop to each damn container and then through each 'href' element. My program is not loop to each image. I know why too. In "Automate the Boring Stuff with Python" his image scraper only scraped one image then clicked the previous button on the webpage. He did not show us how to scrape multiple images from one page. That is the essence I'm missing but I'm having trouble coming up with the solution.

### Day 46: August 23rd, 2018

**Today's Progress:** All of a sudden, my script is not writing to the directory. It's saying that it is not a valid directory. I tried looking up the error but my case seems different. I literally do not know why I'm having such trouble with being able to download all the images from analogworhip.com. I know I'm super close it's just something missing in the while loop or my variables aren't selected correctly. It seems as if they selected correctly though. I tried changing up the soup.select() arguments but now it's not even writing to the directory which is concerning for me. The link attachment contains the code.

**Link:** https://twitter.com/Garrtacular7/status/1032721691510628354

**Thoughts:** Getting every closer. I think I'm going to make a post on Stack Overflow to see if anyone can help me out!

### Day 47: August 24th, 2018

**Today's Progress:** Reading "Automate the Boring Stuff with Python" has helped a ton. From analogworship.com, I was able to extract just the title of the artist and got rid of the extra stuff that come with it like the price and if it was a split or not. I used the split() function and I had to read some documentation on it but overall I was able to figure it out. Now I just need to figure out how to tell the program to loop through each item in the list without repeating just the first element 50 times because that is what the program is doing. I need it to loop through the list's index. The problem is probably coming from the 0th index in the for loop somehow. Overall, I should be able to figure out with relative ease. I can't let frustrations overcome my judgement.

**Link:** This is what the program is doing: https://twitter.com/Garrtacular7/status/1033064100937392128

**Thoughts:** I'm stoked with myself that I was able to extract just the title and disregard the rest of the text that I did not need. I'm starting to understand! Python is very diverse and I love emercing myself in it. I have to keep consistent. On the brightside, I tell myself I have only an hour but I end up coding for much longer than that. I also have had a busy week with band stuff but I'm happy with myself that I have stayed so consistent.

**UPDATE:** I figured out the for loop. I was still only able to extract the first 50 items on the page... This whole infinite scrolling mechanism is throwing things off!

### Day 48: August 25th, 2018

**Today's Progress:** I figured out the while loop to go to every page!

**Thoughts:** Very happy day since I figured out a solution and I'm happy with my progress so far!

### Day 49: August 26th, 2018

**Today's Progress:** Minimum coding done today. Mainly just review

**Thoughts:** I want to make Youtube tutorials!

### Day 50: August 28th, 2018

**Today's Progress:** Working on completing the web scraper so then I can make a Youtube video on it for a tutorial! The way I figured out parsing through each page is pretty genius if I do say so myself. I set it through a while loop and concatenate a number in the form of a string so the request function can pick up on it. Then inside the while loop I have a for loop doing the scraping! So all in all good times. I'm hitting an error because Python is not recognizing some characters. They are foreign characters so it is not writing to the csv file. So i need to make an exception that when the program runs across these, then either skip them or switch up the characters.

**Thoughts:** I need to finish this so I can make the video!

### Day 51: August 29th, 2018

**Today's Progress:** All right so I am on the right track to image scraping. I'm using the same logic as I used for the image scraper and I'm expecting good results. The only problem I am seeming to have is creating the directory. The program is not recognizing the path I'm giving it and it's giving me an error of directory not found. It's such a small bug but I have to know what's going on behind that error. It should take too much more dabbling with though.

**Thoughts:** So my headset mic is a shit mic for recording videos or I just need to figure out how to calibrate it. Once that is done, I'm on the road to recording tutorial videos for scraping and the likes! Hopefully it can all workout!

### Day 52: August 30th, 2018

**Today's Progress:** Listening to Local Man's Awful Podcast and coding. It's awesome hearing my friends talk on an outlet such as a podcast. Anyway, this day has just been looking up information about how to add images to a directory. I can't quite figure it out yet. I want to be able to figure it out because I want to make a text scraping tutorial and an image scraping tutorial. I should have coded at the beginning of the day but I did not do that which I should have. I also have not been keeping a consistent schedule with yoga and exercising and I need to hop back on that.

**Thoughts:** It has been a hecktic week but that should be no excuse. I still find at least an hour to code every day but I need to make a schedule. Like exercise at a certain time and code at a certain time. I also need to get a mic to start recording the videos because I have a big vision for them and I want them to be fun and not as boring as other tutorial videos.

### Day 53: August 31st, 2018

**Today's Progress:** Next project is to scrape all of Amoeba for their releases. There are 6000 plus pages that can be scraped so it should be fun! A ton of scrapeable data! I'm already underway of trying to perform the task. Let's do this!

**Thoughts:** This is probably going to be my next obsession and then I can make a video on it.

### Day 54: September 1st, 2018

**Today's Progress:** Continued working on the project. I need to figure out how to scrape 'tr' from a table on their website. The 'tr' contains everything need to scrape, so when I'm able to extract them, we'll be golden. It's looking like I need to use lxml but everytime I try to import it, it gives me an error 'no module found' it's pretty annoying. I tried uninstalling it, updating it, and reinstalling it. Nothing seems to work. I will have to fiddle with it later some more.

**Thoughts:** This is a good data science project. Implementing a large data set and using scraping to extract everything from a music store seems fun. It just needs to be executed now.

### Day 55: September 3rd, 2018

**Today's Progress:** Inching ever closer to figuring out how to image scrape. When I can figure out both image and text scraping, we are golden. It is fun because I'm on storenvy scraping all images from the site on a certain record label. The label has interesting images. 

**Thoughts:** It's been a journey but I'm getting so much better at it. I'm thinking more programmatically and it's almost clicking. I can feel it. There's still a lot I have to learn but it's coming so much easier. I can't wait for school to start so I can kick ass in my coding classes.

### Day 56: September 4th, 2018

**Today's Progress:** FINALLY! I figured out how to scrape images! My script is super small too like no more than 25 lines of code. Now I can use this as a template and be able to scrape even more images from even more websites.

**Thoughts:** It's about to get serious people... it's about to get serious...

### Day 57: September 5th, 2018

**Today's Progress:** FINALLY my project of scraping all the images from analogworship is complete! I literally just downloaded 1600 + images from the websites catalog with complete and utter ease. I finally figured it out and it feels great! All of the images are in a folder nice and neat and it's all black metal or noise records album art. The script is actually very short and here it is.

**Link:** https://github.com/gantgarrett/Projects/blob/master/analogworshipimagescraper.py

**Thoughts:** Now I'm just waiting for my book to come in, "Practical Web Scraping for Data Science" and I can't wait to dive into that. I mean the work I am doing is practical but I'm ready to delve even further. Plus the name of the book stuck out to me like a sore thumb and it spoke to me on so many levels. Can't wait!

### Day 58: September 6th, 2018

**Today's Progress:** Started recording for Youtube.

**Thoughts:** T'was fun.

### Day 59: September 7th, 2018

**Today's Progress:** Released my first web scraping video on Youtube. It was all about scraping multiple images from a website.

**Link:** https://www.youtube.com/watch?v=CNB6UPSOeSw

**Thoughts:** It was dank and it already has 3 likes on it! :) 

### Day 60: September 9th, 2018

**Today's Progress:** Started another video!

**Thoughts:** It seems as if making these videos are pretty much just for me!

### Day 61: September 10th, 2018

**Today's Progress:** Recorded another video and it was just me messing around R and web scraping.

**Link:** https://www.youtube.com/watch?v=v9wYETTPjdc&t=492s

**Thoughts:** I think they are a blast to make!

### Day 62: September 11th, 2018

**Today's Progress:** Another video created!

**Link:** https://www.youtube.com/watch?v=7xyFxAocVUU&t=35s

**Thoughts:** Check it out! :)

### Day 63: September 12th, 2018

**Today's Progress:** Started working with Django and I'm having a blast! The book I'm reading is on hecka fleek!

**Link:** https://youtu.be/8_N9yFq7520

**Thoughts:** Can't wait to start developing web skills! It's actually a lot of fun and I don't know why! LOL!

### Day 64: September 13th, 2018

**Today's Progress:** Filmed more footage of coding. I have 2 subscribers already! Whoot! I'm reading this book about the Django framework and it's great. I'm copying and pasting a lot of code but it is helping me understand. I am overwhelmed but this is only the third hour of me messing around the Django so I can't beat myself up too bad.

**Link:** https://www.youtube.com/watch?v=XKEN-HMtO70&t=6s

**Thoughts:** Going to continue to post videos!

### Day 65: September 14, 2018

**Today's Progress:** I woke up early today, drank some water, played Doom and then started filming and coding. Filming helps me to be accountable for my progress and it is helping. I'm making a blog website!

**Thoughts:** Going to upload the video to YouTube now. In all reality it is not terribly interesting content but it is just for me! If people wanna watch they can watch!

### Day 66: September 17th, 2018

**Today's Progress:** So I had to miss two days over the weekend because I was giggin' and going to show and writing a new demo but I still managed to get coding in!

**Link:** https://www.youtube.com/watch?v=n7xRCeIkY2Q

**Thoughts:** Youtube is a great platform to keep myself accountable!

### Day 67: September 18th, 2018

**Today's Progress:** Working along in my book and just scratching the surface with the Django framework! But it is a lot of fun yet challenging!

**Link:** https://www.youtube.com/watch?v=gkfZkeq94gA&t=348s

**Thoughts:** It's working, it's working!

### Day 68: September 19th, 2018

**Today's Progress:** Still continuing to work in my book and film all of my errors and frustration

**Link:** https://www.youtube.com/watch?v=ukYuVOIOw-k&t=100s

**Thoughts:** More filming and streaming and tutorials to come!

### Day 69: September 20th, 2018

**Today's Progress:** Okay, so I haven't updated this in a while and that is why all of the previous entries are short. So today, right now, which is 7:03am I am happy to say that school is about to start and it's going to be a great quarter! I got my job back as SI Leader and I will be working under Dr. Murphy. It's real cool. I thought Murphy was a great teacher when it came to CSE 330. So having him teach the intro class should be great! I continued to film my progress of working through my book and it is a lot of fun I just can't copy and paste text which is annoy when I'm having to type long URLs and such but such is life.

**Thoughts:** I'm more than halfway through the book. I also had orientation yesterday for SI and I met someone who needed work done with R. I was like, "I'm your man!" So hopefully the ball gets rolling on that. It has to do with text analysis of interviews and I was like yes a data science project! I will do it for free, do a good job and then hopefully get recommend by her to more and more people. Happy days to come.

### Day 70: September 21st, 2018

**Today's Progress:** Filmed a YouTube video and it felt good!

**Thoughts:** About to start school next week and I'm excited to do all of my programming classes!

### Day 71: September 22nd, 2018

**Today's Progress:** Filmed another video but I'm starting to think that they are not a good idea because I'll just code for one hour only and think that it's okay when I need to dedicated more hours!

**Thoughts:** I still need to do some sort of footage though for the sake of YouTube content!

### Day 72: Septmeber 23rd, 2018

**Today's Progresss:** Okay, I bought a laptop and install Ubuntu on it! It's what I'm typing on now! So far I love it, I thought the installation process was going to be a lot harder but it wasn't!

**Thoughts:** So far, installing applications are through the terminal. No wonder why people stray away from this OS... It's not difficult if you know your way around a computer!

### Day 73: September 24th, 2018

**Today's Progress:** I'm here at school right now on pretty much a 12 hour gap. My class starts in 30 minutes and it's called JAVA programming which I'm really excited for. I installed the IDE and installed the latest version of JAVA so I'm all set. I'm super pumped to see what it's all about!

**Thoughts:** The indie hacker episode from code newbies is very inspiring! I feel like it's right up my alley. I really need to find a project to work on and dedicate my time. Try to build a product that I would buy myself. I usually buy games but mainly big gameI could do a Craigslist scraper but that has already been done. I just need to find the hole in the market and pinpoint it and start building. I really do love programming so being able to strengthen my technically skills is what I need to do.

### Day 74: September 25th, 2018

**Today's Progress:** Okay so this challenge has gotten a lot easier since I'm basically forced to program now because of all of my classes. Pretty much each class I am taking is all about programming which I am so ready for. I finally made it to all my upper division courses and I'm inching ever forward towards graduation. I basically did lab work for 3 and a half hours trying to operate on a virtual machine. It was fun yet challenging.

**Thoughts:** School's been a lot of fun so far. I just sucks that I ruined my reputation from dating Jackie and now I don't even want to partake in club activities. Oh well, that's how it all works out. My rep's not ruined it's just I'm all paranoid now. I don't want to run into certain people on campus but literally that's just how it goes. Some internal struggle stuff that I need to let go.

### Day 75: September 26th, 2018

**Today's Progress:** I wrote the assigned Java programs for my Java programming class with ease. What would programmers do without the Google?

**Thoughts:** It's so rewarding finishing a working program. Even though they are small programs, I'm going to induldge in every W I earn!

### Day 76: Septmeber 27th, 2018

**Today;s Progress:** My scripting class is going great so far. It's kind of like a jigsaw puzzle and trouble shooting is fun yet frustrating but it feels soooo good once you figure out the problem. It gives me so much satisfaction like no other. I also had a good day teaching C++. Teaching coding also brings me such satisfaction.

**Thoughts:** I have learned so much over this journey. It's excruatiatingly fantastic. I have so much more to learn too!

### Day 77: September 28th, 2018

**Today's Progress:** Dabbled with WireShark because my net working class has me curious. I'm currently sitting in a coffee shop wiresharking lol. I don't know how to make sense of the data though. I will look more into it. I should be studying but I was like nah Wireshark.

**Thoughts:** I need to understand these concepts so I can be more secure and learn how t fight off attackers. It's super d dupper fun.

### Day 78: September 29th, 2018

**Today's Progress:** Worked on bash scripts today and it was cool. Bash is the most complex language I have used yet. There are just a million different commands you can perform. It is fun though so I'm going to complete that my g.

**Thoughts:** To be fluent in bash is to be fluent in everything lol.

### Day 79: September 30th, 2018

**Today's Progress:** Worked on some webscrapers for imdb to check the ratings of Spongebob by season. I'm still manipulating the data so it doesn't look pretty but it will soon.

**Thoughts:** A thought dawned on me that I need to improve my tech skills because it's something I can sell myself on and I need to make money. Learning software engineering is important and I will take it far.

### Day 80 - 100: December 2nd, 2018

**Today's Progress:** Okay so I finished the challenge but I stopped logging my progress in here starting at day 80... I lost the motivation for true self reflection. It's true. I lost touch with myself for a bit and I'm strugglilng with what the future holds. I have the imposter syndrome hard right now. When school started kicking in more, I started writing less in here. It sucks because  I am learning but not at the rate with which I like. I feel regression. Yet I have to get over this obsticle.

**Thoughts:** Even though I didn't start writing in here, I did post to twitter my progress and I have gotten a positive response so far. So now I need to keep progressing.
